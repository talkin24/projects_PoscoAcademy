<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pose_estimation_cv2.ipynb","provenance":[],"authorship_tag":"ABX9TyNMRe+hNQxFx0kDxHuXvDEN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5JnABJZy-6VE","colab_type":"code","outputId":"a28f4e92-07d7-4346-f008-55a15f5ccd0e","executionInfo":{"status":"ok","timestamp":1590077541104,"user_tz":-540,"elapsed":26007,"user":{"displayName":"이다연","photoUrl":"","userId":"03185589570639830741"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/gdrive',force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZKSzxejpWQGw","colab_type":"text"},"source":["# 이미지 예시"]},{"cell_type":"code","metadata":{"id":"9BO0Q3HFACAi","colab_type":"code","outputId":"3a2be48b-6375-4762-a8cd-e2c42f5ba83d","executionInfo":{"status":"ok","timestamp":1590077546848,"user_tz":-540,"elapsed":4847,"user":{"displayName":"이다연","photoUrl":"","userId":"03185589570639830741"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["! ls \"/gdrive/My Drive/pose_estimation_ex/input\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["me_london.mp4  me_studying.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qRiz4wkaAayC","colab_type":"code","colab":{}},"source":["import cv2\n","import time\n","import numpy as np\n","import sys\n","import os\n","\n","def proc(module, img):\n","    if module == \"mpi\":\n","        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.prototxt\"\n","        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.caffemodel\"\n","        nPoints = 15\n","        POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13]]\n","    else:\n","        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.prototxt\"\n","        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.caffemodel\"\n","        nPoints = 18\n","        POSE_PAIRS = [[1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n","    print(\"/gdrive/My Drive/pose_estimation_ex/input/\" + img)\n","    frame = cv2.imread(\"/gdrive/My Drive/pose_estimation_ex/input/\"+img)\n","    frameCopy = np.copy(frame)\n","    frameWidth = frame.shape[1]\n","    frameHeight = frame.shape[0]\n","    threshold = 0.1\n","    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n","    t = time.time()\n","    inWidth = 368\n","    inHeight = 368\n","    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n","                              (0, 0, 0), swapRB=False, crop=False)\n","    net.setInput(inpBlob)\n","    output = net.forward()\n","    print(\"완료 : {:.3f}\".format(time.time() - t))\n","    H = output.shape[2]\n","    W = output.shape[3]\n","    points = []\n","    for i in range(nPoints):\n","        probMap = output[0, i, :, :]\n","        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n","        x = (frameWidth * point[0]) / W\n","        y = (frameHeight * point[1]) / H\n","        if prob > threshold : \n","            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n","            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n","            points.append((int(x), int(y)))\n","        else :\n","            points.append(None)\n","    for pair in POSE_PAIRS:\n","        partA = pair[0]\n","        partB = pair[1]\n","        if points[partA] and points[partB]:\n","            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n","            cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n","    cv2.imwrite('/gdrive/My Drive/pose_estimation_ex/output/' + module + \"_\" + img, frame)\n","\n","if __name__ == '__main__':\n","    module = [\"mpi\",\"coco\"]\n","    for i in module:\n","        for j in os.listdir(\"/gdrive/My Drive/pose_estimation_ex/input\"):\n","        \tif j[-3:] in ['jpg','png','peg']:\n","        \t\tproc(i, j)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HLrQuss-WMBW","colab_type":"text"},"source":["# video 예시"]},{"cell_type":"code","metadata":{"id":"youh05FkH1Fu","colab_type":"code","outputId":"d378b6d0-0a0a-4bfa-fca6-9a5e4528e786","executionInfo":{"status":"ok","timestamp":1590048985699,"user_tz":-540,"elapsed":9913,"user":{"displayName":"이다연","photoUrl":"","userId":"03185589570639830741"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["! ls \"/gdrive/My Drive/pose_estimation_ex/input\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["me_standing.mp4  me_studying.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JFV3vHGHCaar","colab_type":"code","outputId":"b5919508-b5ca-405c-99bd-b68d840f6984","executionInfo":{"status":"ok","timestamp":1590079589577,"user_tz":-540,"elapsed":2037325,"user":{"displayName":"이다연","photoUrl":"","userId":"03185589570639830741"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["import cv2\n","import time\n","import numpy as np\n","import os\n","\n","def proc(module, video):\n","    if module is \"coco\":\n","        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.prototxt\"\n","        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.caffemodel\"\n","        nPoints = 18\n","        POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n","\n","    elif module is \"mpi\":\n","        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.prototxt\"\n","        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.caffemodel\"\n","        nPoints = 15\n","        POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n","    inWidth = 368\n","    inHeight = 368\n","    threshold = 0.1\n","    input_source = \"/gdrive/My Drive/pose_estimation_ex/input/\" + video\n","    print(input_source)\n","    cap = cv2.VideoCapture(input_source)\n","\n","    hasFrame, frame = cap.read()\n","    vid_writer = cv2.VideoWriter('/gdrive/My Drive/pose_estimation_ex/output/' + video.split(\".\")[0] + \"_\"+ module + '.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame.shape[1],frame.shape[0]))\n","    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n","    while cv2.waitKey(1) < 0:\n","        t = time.time()\n","        hasFrame, frame = cap.read()\n","        frameCopy = np.copy(frame)\n","        if not hasFrame:\n","            cv2.waitKey()\n","            break\n","        frameWidth = frame.shape[1]\n","        frameHeight = frame.shape[0]\n","        inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n","                                  (0, 0, 0), swapRB=False, crop=False)\n","        net.setInput(inpBlob)\n","        output = net.forward()\n","        H = output.shape[2]\n","        W = output.shape[3]\n","        points = []\n","        for i in range(nPoints):\n","            probMap = output[0, i, :, :]\n","            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n","            x = (frameWidth * point[0]) / W\n","            y = (frameHeight * point[1]) / H\n","            if prob > threshold : \n","                cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n","                cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n","                points.append((int(x), int(y)))\n","            else :\n","                points.append(None)\n","        for pair in POSE_PAIRS:\n","            partA = pair[0]\n","            partB = pair[1]\n","            if points[partA] and points[partB]:\n","                cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3, lineType=cv2.LINE_AA)\n","                cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n","                cv2.circle(frame, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n","        cv2.putText(frame, \"Test Time = {:.2f} sec\".format(time.time() - t), (50, 50), cv2.FONT_HERSHEY_COMPLEX, .8, (255, 50, 0), 2, lineType=cv2.LINE_AA)\n","        vid_writer.write(frame)\n","    vid_writer.release()\n","\n","if __name__ == '__main__':\n","    module = [\"mpi\",\"coco\"]\n","    for i in module:\n","        for j in os.listdir(\"/gdrive/My Drive/pose_estimation_ex/input\"):\n","            if j[-3:] in ['mp4','avi']:\n","                proc(i, j)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/pose_estimation_ex/input/me_london.mp4\n","/gdrive/My Drive/pose_estimation_ex/input/me_london.mp4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P2zjcjVGH7JD","colab_type":"code","outputId":"1719337f-03e2-466b-959a-da20a835a0c3","executionInfo":{"status":"error","timestamp":1590083680035,"user_tz":-540,"elapsed":650,"user":{"displayName":"이다연","photoUrl":"","userId":"03185589570639830741"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import face_recognition\n","import os\n","import cv2\n","import pickle\n","import time\n","\n","KNOWN_FACES_DIR='known_faces'\n","\n","TOLERANCE=0.6\n","FRAME_THICKNESS=3\n","FONT_THICKNESS=2\n","MODEL='cnn'\n","\n","video=cv2.VideoCapture('/gdrive/My Drive/pose_estimation_ex/input/couple.mp4') # 경로와 파일이름만 변경하면 됨\n","\n","print('loading known faces')\n","\n","known_faces=[]\n","known_names=[]\n","\n","for name in os.listdir(KNOWN_FACES_DIR):\n","  for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n","    # encoding=face_recognition.face_encodings(image)[0]\n","    encoding=pickle.load(open(f\"{name}/{filename}\",'rb'))\n","    known_faces.append(encoding)\n","    known_names.append(int(name))\n","\n","if len(known_names)>0:\n","  next_id=max(known_names)+1\n","else:\n","  next_id=0\n","\n","print(\"processing unkown faces\")\n","\n","while True:\n","  ret, image=video.read()\n","\n","  locations=face_recognition.face_locations(image,model=MODEL)\n","  encodings=face_recognition.face_encodings(image,locations)\n","\n","  for face_encoding, face_location in zip(encodings, locations):\n","    results=face_recognition.compare_faces(known_faces,face_encoding,TOLERANCE)\n","    match=None\n","    if True in results:\n","      match=known_names[results.index(True)]\n","      print(f'Match found: {match}')\n","    else:\n","      match=str(next_id)\n","      next_id+=1\n","      known_names.append(match)\n","      known_faces.append(face_encoding)\n","      os.mkdir(f'{KNOWN_FACES_DIR}/{match}')\n","      pickle.dump(face_encoding,open(f'{KNOWN_FACES_DIR}/{match}/{match}-{int(time.time())}.pkl','wb'))\n","\n","    top_left=(face_location[3],face_location[0])\n","    bottom_right=(face_location[1],face_location[2])\n","    color=[0,255,0]\n","    cv2.rectangle(image,top_left,bottom_right,color,FRAME_THICKNESS)\n","\n","    top_left=(face_location[3],face_location[2])\n","    bottom_right=(face_location[1],face_location[2]+22)\n","    dv2.rectangle(image,top_left,bottom_right,color,FRAME_THICKNESS)\n","    cv2.putText(image,match,(face_location[3]+10,face_location[2]+15),cv2.FONT_HERSHEY_SIMPLEX,0.5,(200,200,200)\n","\n","  cv2.imshow(\"jk\",image)\n","  if cv2.waitKey(1) & 0xFF==ord('q'):\n","    break\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-2390ee7baca7>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    cv2.imshow(\"jk\",image)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"NBc4UE__SFyu","colab_type":"code","colab":{}},"source":["\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hhz0aiIGTEgu","colab_type":"code","outputId":"c4aab9ef-6a65-4f7b-e2ce-fb0bd4efa6a3","executionInfo":{"status":"ok","timestamp":1590082473567,"user_tz":-540,"elapsed":30468,"user":{"displayName":"이다연","photoUrl":"","userId":"03185589570639830741"}},"colab":{"base_uri":"https://localhost:8080/","height":325}},"source":["! pip install face_recognition"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting face_recognition\n","  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n","Collecting face-recognition-models>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n","\u001b[K     |████████████████████████████████| 100.2MB 79kB/s \n","\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=0222eafbc46b2c0eb64ad16960a043c3f726a73141c82873d61cfb7de4476d4d\n","  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BrN73TFkTGA-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
=======
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pose_estimation_cv2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JnABJZy-6VE",
        "colab_type": "code",
        "outputId": "a28f4e92-07d7-4346-f008-55a15f5ccd0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKSzxejpWQGw",
        "colab_type": "text"
      },
      "source": [
        "# 이미지 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BO0Q3HFACAi",
        "colab_type": "code",
        "outputId": "3a2be48b-6375-4762-a8cd-e2c42f5ba83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! ls \"/gdrive/My Drive/pose_estimation_ex/input\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "me_london.mp4  me_studying.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRiz4wkaAayC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def proc(module, img):\n",
        "    if module == \"mpi\":\n",
        "        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.prototxt\"\n",
        "        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.caffemodel\"\n",
        "        nPoints = 15\n",
        "        POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13]]\n",
        "    else:\n",
        "        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.prototxt\"\n",
        "        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.caffemodel\"\n",
        "        nPoints = 18\n",
        "        POSE_PAIRS = [[1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
        "    print(\"/gdrive/My Drive/pose_estimation_ex/input/\" + img)\n",
        "    frame = cv2.imread(\"/gdrive/My Drive/pose_estimation_ex/input/\"+img)\n",
        "    frameCopy = np.copy(frame)\n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "    threshold = 0.1\n",
        "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
        "    t = time.time()\n",
        "    inWidth = 368\n",
        "    inHeight = 368\n",
        "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
        "                              (0, 0, 0), swapRB=False, crop=False)\n",
        "    net.setInput(inpBlob)\n",
        "    output = net.forward()\n",
        "    print(\"완료 : {:.3f}\".format(time.time() - t))\n",
        "    H = output.shape[2]\n",
        "    W = output.shape[3]\n",
        "    points = []\n",
        "    for i in range(nPoints):\n",
        "        probMap = output[0, i, :, :]\n",
        "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
        "        x = (frameWidth * point[0]) / W\n",
        "        y = (frameHeight * point[1]) / H\n",
        "        if prob > threshold : \n",
        "            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
        "            points.append((int(x), int(y)))\n",
        "        else :\n",
        "            points.append(None)\n",
        "    for pair in POSE_PAIRS:\n",
        "        partA = pair[0]\n",
        "        partB = pair[1]\n",
        "        if points[partA] and points[partB]:\n",
        "            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
        "            cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "    cv2.imwrite('/gdrive/My Drive/pose_estimation_ex/output/' + module + \"_\" + img, frame)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    module = [\"mpi\",\"coco\"]\n",
        "    for i in module:\n",
        "        for j in os.listdir(\"/gdrive/My Drive/pose_estimation_ex/input\"):\n",
        "        \tif j[-3:] in ['jpg','png','peg']:\n",
        "        \t\tproc(i, j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLrQuss-WMBW",
        "colab_type": "text"
      },
      "source": [
        "# video 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "youh05FkH1Fu",
        "colab_type": "code",
        "outputId": "d378b6d0-0a0a-4bfa-fca6-9a5e4528e786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! ls \"/gdrive/My Drive/pose_estimation_ex/input\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "me_standing.mp4  me_studying.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFV3vHGHCaar",
        "colab_type": "code",
        "outputId": "b5919508-b5ca-405c-99bd-b68d840f6984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def proc(module, video):\n",
        "    if module is \"coco\":\n",
        "        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.prototxt\"\n",
        "        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/coco.caffemodel\"\n",
        "        nPoints = 18\n",
        "        POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
        "\n",
        "    elif module is \"mpi\":\n",
        "        protoFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.prototxt\"\n",
        "        weightsFile = \"/gdrive/My Drive/pose_estimation_ex/model/mpi.caffemodel\"\n",
        "        nPoints = 15\n",
        "        POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
        "    inWidth = 368\n",
        "    inHeight = 368\n",
        "    threshold = 0.1\n",
        "    input_source = \"/gdrive/My Drive/pose_estimation_ex/input/\" + video\n",
        "    print(input_source)\n",
        "    cap = cv2.VideoCapture(input_source)\n",
        "\n",
        "    hasFrame, frame = cap.read()\n",
        "    vid_writer = cv2.VideoWriter('/gdrive/My Drive/pose_estimation_ex/output/' + video.split(\".\")[0] + \"_\"+ module + '.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame.shape[1],frame.shape[0]))\n",
        "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
        "    while cv2.waitKey(1) < 0:\n",
        "        t = time.time()\n",
        "        hasFrame, frame = cap.read()\n",
        "        frameCopy = np.copy(frame)\n",
        "        if not hasFrame:\n",
        "            cv2.waitKey()\n",
        "            break\n",
        "        frameWidth = frame.shape[1]\n",
        "        frameHeight = frame.shape[0]\n",
        "        inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
        "                                  (0, 0, 0), swapRB=False, crop=False)\n",
        "        net.setInput(inpBlob)\n",
        "        output = net.forward()\n",
        "        H = output.shape[2]\n",
        "        W = output.shape[3]\n",
        "        points = []\n",
        "        for i in range(nPoints):\n",
        "            probMap = output[0, i, :, :]\n",
        "            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
        "            x = (frameWidth * point[0]) / W\n",
        "            y = (frameHeight * point[1]) / H\n",
        "            if prob > threshold : \n",
        "                cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "                cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
        "                points.append((int(x), int(y)))\n",
        "            else :\n",
        "                points.append(None)\n",
        "        for pair in POSE_PAIRS:\n",
        "            partA = pair[0]\n",
        "            partB = pair[1]\n",
        "            if points[partA] and points[partB]:\n",
        "                cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3, lineType=cv2.LINE_AA)\n",
        "                cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "                cv2.circle(frame, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "        cv2.putText(frame, \"Test Time = {:.2f} sec\".format(time.time() - t), (50, 50), cv2.FONT_HERSHEY_COMPLEX, .8, (255, 50, 0), 2, lineType=cv2.LINE_AA)\n",
        "        vid_writer.write(frame)\n",
        "    vid_writer.release()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    module = [\"mpi\",\"coco\"]\n",
        "    for i in module:\n",
        "        for j in os.listdir(\"/gdrive/My Drive/pose_estimation_ex/input\"):\n",
        "            if j[-3:] in ['mp4','avi']:\n",
        "                proc(i, j)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/pose_estimation_ex/input/me_london.mp4\n",
            "/gdrive/My Drive/pose_estimation_ex/input/me_london.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2zjcjVGH7JD",
        "colab_type": "code",
        "outputId": "1719337f-03e2-466b-959a-da20a835a0c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import face_recognition\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "KNOWN_FACES_DIR='known_faces'\n",
        "\n",
        "TOLERANCE=0.6\n",
        "FRAME_THICKNESS=3\n",
        "FONT_THICKNESS=2\n",
        "MODEL='cnn'\n",
        "\n",
        "video=cv2.VideoCapture('/gdrive/My Drive/pose_estimation_ex/input/couple.mp4') # 경로와 파일이름만 변경하면 됨\n",
        "\n",
        "print('loading known faces')\n",
        "\n",
        "known_faces=[]\n",
        "known_names=[]\n",
        "\n",
        "for name in os.listdir(KNOWN_FACES_DIR):\n",
        "  for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
        "    # encoding=face_recognition.face_encodings(image)[0]\n",
        "    encoding=pickle.load(open(f\"{name}/{filename}\",'rb'))\n",
        "    known_faces.append(encoding)\n",
        "    known_names.append(int(name))\n",
        "\n",
        "if len(known_names)>0:\n",
        "  next_id=max(known_names)+1\n",
        "else:\n",
        "  next_id=0\n",
        "\n",
        "print(\"processing unkown faces\")\n",
        "\n",
        "while True:\n",
        "  ret, image=video.read()\n",
        "\n",
        "  locations=face_recognition.face_locations(image,model=MODEL)\n",
        "  encodings=face_recognition.face_encodings(image,locations)\n",
        "\n",
        "  for face_encoding, face_location in zip(encodings, locations):\n",
        "    results=face_recognition.compare_faces(known_faces,face_encoding,TOLERANCE)\n",
        "    match=None\n",
        "    if True in results:\n",
        "      match=known_names[results.index(True)]\n",
        "      print(f'Match found: {match}')\n",
        "    else:\n",
        "      match=str(next_id)\n",
        "      next_id+=1\n",
        "      known_names.append(match)\n",
        "      known_faces.append(face_encoding)\n",
        "      os.mkdir(f'{KNOWN_FACES_DIR}/{match}')\n",
        "      pickle.dump(face_encoding,open(f'{KNOWN_FACES_DIR}/{match}/{match}-{int(time.time())}.pkl','wb'))\n",
        "\n",
        "    top_left=(face_location[3],face_location[0])\n",
        "    bottom_right=(face_location[1],face_location[2])\n",
        "    color=[0,255,0]\n",
        "    cv2.rectangle(image,top_left,bottom_right,color,FRAME_THICKNESS)\n",
        "\n",
        "    top_left=(face_location[3],face_location[2])\n",
        "    bottom_right=(face_location[1],face_location[2]+22)\n",
        "    dv2.rectangle(image,top_left,bottom_right,color,FRAME_THICKNESS)\n",
        "    cv2.putText(image,match,(face_location[3]+10,face_location[2]+15),cv2.FONT_HERSHEY_SIMPLEX,0.5,(200,200,200)\n",
        "\n",
        "  cv2.imshow(\"jk\",image)\n",
        "  if cv2.waitKey(1) & 0xFF==ord('q'):\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-2390ee7baca7>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    cv2.imshow(\"jk\",image)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBc4UE__SFyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhz0aiIGTEgu",
        "colab_type": "code",
        "outputId": "c4aab9ef-6a65-4f7b-e2ce-fb0bd4efa6a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "! pip install face_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 79kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=0222eafbc46b2c0eb64ad16960a043c3f726a73141c82873d61cfb7de4476d4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrN73TFkTGA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
>>>>>>> master
